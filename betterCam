#!/usr/bin/env python

import argparse
import configparser
import cv2
import os
import numpy

class camData:

    def show(self , frame):
        cv2.imshow(self.name , frame)

    def get(self):
        ret, frame = self.cap.read()
        if(ret):
            if(self.res[1] != frame.shape[0] or self.res[0] != frame.shape[1]):
                self.res[1] = frame.shape[0]
                self.res[0] = frame.shape[1]
                self.ones = numpy.ones((self.res[1] , self.res[0]) , numpy.uint8)
                self.black = 0 * self.ones
                self.white = 255 * self.ones
                self.whitef32 = self.white.astype("float32")
            return frame
        else:
            return None

    def __init__(self , cam = None):

        # script directory
        self.script_path = os.path.dirname(os.path.realpath(__file__))

        # reading configuration file 
        self.config = configparser.ConfigParser()
        self.config.read(os.path.join(self.script_path , "betterCam_config"))
       
        self.buff = int(self.config["perspectiveMatrix"]["buffer"])
        
        self.k_pix = int(self.config["fragment"]["k_pix"])
        self.f_buff = int(self.config["smooth"]["f_buff"])
        self.l_col = float(self.config["levels1"]["l_col"])

        # getting camera
        if(cam == None):
            self.camera = 0
        else:
            self.camera = int(self.config[cam]["number"])

        self.cap = cv2.VideoCapture(self.camera)

        # perspective matrix

        self.m_avg = None

        if(cam == None):
            self.res = [1920 , 1080]
        else:
            self.res = list(map(lambda x : int(x) , self.config[cam]["aspectratio"].split("x")))
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.res[0])
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.res[1])

        # window for cv
        if(cam == None):
            self.name = "frame"
            cv2.namedWindow('frame' , cv2.WINDOW_GUI_NORMAL)
        else:
            self.name = cam
            cv2.namedWindow(cam , cv2.WINDOW_GUI_NORMAL)

        # for freazing
        self.freeze = False
        self.ret = None
        self.frame = None

        # for denoising 
        self.ones = numpy.ones((self.res[1] , self.res[0]) , numpy.uint8)
        self.black = 0 * self.ones
        self.white = 255 * self.ones
        self.whitef32 = self.white.astype("float32")
        
        self.blur_kernel = numpy.ones((self.k_pix , self.k_pix) , dtype = numpy.float32) 
        self.blur_kernel = self.blur_kernel / numpy.sum(self.blur_kernel.flatten())

        # list of perspecive matrixes
        self.m_list = []

        # list of frames for smoothing
        self.frame_buff = []
        self.avg = False

        # points surrounfing the QR code available
        self.got_points = False

        # points surrounfing the QR code
        self.pointsglob = None

        # aruco markers
        self.aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_250)
        self.parameters =  cv2.aruco.DetectorParameters_create()

def applyDenoise(warped , aux):

    hls = cv2.cvtColor(warped , cv2.COLOR_BGR2HLS)

    gray = cv2.cvtColor(warped , cv2.COLOR_BGR2GRAY) 
    gray = 255 - gray
    gray = gray.astype("float32")

    #gray[0:3 , :] = 0.0
    #gray[gray.shape[0] - 3 : gray.shape[0] , :] = 0.0
    #gray[: , 0:3] = 0.0
    #gray[: , gray.shape[1] - 3 : gray.shape[1]] = 0.0

    blured_gray = cv2.filter2D(gray , -1 , aux.blur_kernel)
    
    stdv = numpy.sqrt(numpy.mean(((gray - blured_gray) * (gray - blured_gray)).flatten()))

    h_res = hls[: , : , 0]
    l_res = numpy.where((gray - blured_gray) > aux.l_col * stdv , hls[: , : , 1] , aux.white)
    s_res = hls[: , : , 2]
    

    warped = cv2.cvtColor(cv2.merge((h_res , l_res , s_res)) , cv2.COLOR_HLS2BGR)
    
    return (warped , aux)

def applyContours(warped , aux):

    #hls = cv2.cvtColor(warped , cv2.COLOR_BGR2HLS)

    gray = cv2.cvtColor(warped , cv2.COLOR_BGR2GRAY) 
    gray = 255 - gray
    gray = gray.astype("float32")

    #gray[0:3 , :] = 0.0
    #gray[gray.shape[0] - 3 : gray.shape[0] , :] = 0.0
    #gray[: , 0:3] = 0.0
    #gray[: , gray.shape[1] - 3 : gray.shape[1]] = 0.0

    blured_gray = cv2.filter2D(gray , -1 , aux.blur_kernel)
    
    stdv = numpy.sqrt(numpy.mean(((gray - blured_gray) * (gray - blured_gray)).flatten()))

    l_res = numpy.where((gray - blured_gray) > aux.l_col * stdv , aux.white , aux.black)

    contours, hierarchy = cv2.findContours(l_res, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    wh = 255 * aux.ones 
    cv2.drawContours(wh, contours, -1, (0,0,0), -1)

    #print(len(contours))

    return (wh , aux)

def getFrame(frame , aux):
    fr = aux.get()
    if(not fr is None):
        return (fr , aux)
    else:
        return None

def getFrameAvg(frame , aux):
    warped = aux.get()
    if(not warped is None):
        aux.frame_buff.append(warped)
        if(len(aux.frame_buff) > aux.f_buff):
            aux.frame_buff.pop(0)
       
        smooth = numpy.zeros(warped.shape , numpy.float32)

        for f in aux.frame_buff:
            smooth = smooth + f

        smooth = smooth / len(aux.frame_buff)
        smooth = smooth.astype(warped.dtype)
        warped = smooth
        return (warped , aux)
    else:
        return None

def invertColors(frame , aux):
    warped = 255 - frame
    return (warped , aux)

def getMarkers(frame , aux):

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, aux.aruco_dict, parameters=aux.parameters)
   
    pts = None

    ok = True
    
    if(len(corners) == 4):
        allids = [0 , 1 , 2 , 3]
        pts = [None , None , None , None]
        for i in range(4):
            if(ids[i][0] <= 3 and ids[i][0] >= 0):
                pts[ids[i][0]] = [
                        (int(corners[i][0][0][0]) , int(corners[i][0][0][1])) ,
                        (int(corners[i][0][1][0]) , int(corners[i][0][1][1])) ,
                        (int(corners[i][0][2][0]) , int(corners[i][0][2][1])) ,
                        (int(corners[i][0][3][0]) , int(corners[i][0][3][1]))
                        ];

        ok = ok and (not None in pts)
    else:
        ok = False

    # update matrix
    if(ok):
        aux.pointsglob = pts
        src = numpy.array([aux.pointsglob[0][2] , aux.pointsglob[1][3] , aux.pointsglob[3][0] , aux.pointsglob[2][1]] , numpy.float32)
        dst = numpy.array([[frame.shape[1] , frame.shape[0]] , [0.0 , frame.shape[0]] , [0.0 , 0.0] , [frame.shape[1] , 0.0]] , numpy.float32)
        m = cv2.getPerspectiveTransform(src , dst)
        aux.m_list.append(m)
        if(len(aux.m_list) > aux.buff):
            aux.m_list.pop(0)
        aux.m_avg = numpy.zeros(m.shape , dtype = m.dtype)
        for mm in aux.m_list:
            aux.m_avg = aux.m_avg + mm
        aux.m_avg = aux.m_avg / float(len(aux.m_list))
    
    if(aux.m_avg is None):
        return (frame , aux)
    else:
        warped = cv2.warpPerspective(frame , aux.m_avg , (frame.shape[1] , frame.shape[0]))
        return (warped , aux)

if(__name__ == "__main__"):

    # parsing command line arguments 
    parser = argparse.ArgumentParser(description = """
    Use web cam as blackboard.

    Keyboard shortcuts:

    q - quit
    r - pop tool from stack
    w - push ARUCO marker warping to the tool stack
    i - invert colors
""")
    parser.add_argument("--camera" , "-c" , help = "Camera to use. Each camera name should be a section in the config file with an associated number and aspectratio.")
    args = parser.parse_args() 
   
    mainAux = camData(cam = args.camera)
    tools = [getFrame]
    frame = None
    pauseAll = False

    # main loop

    try: 
        while(True):

            if(not pauseAll):

                for t in tools:
                    frame , mainAux = t(frame , mainAux)

                    mainAux.show(frame)

            key = cv2.waitKey(1)
            if(key == ord('q')):
                break
            elif(key == ord('w')):
                tools = [getFrame]
            elif(key == ord('i')):
                tools = [getFrameAvg , getMarkers , applyDenoise , invertColors]
            elif(key == ord('d')):
                tools = [getFrameAvg , getMarkers , applyDenoise]
            elif(key == ord('c')):
                tools = [getFrameAvg , getMarkers , applyContours , invertColors]
            elif(key == ord('o')):
                tools = [getFrame , getMarkers , applyDenoise , invertColors]
            elif(key == ord('f')):
                tools = [getFrame , getMarkers , applyDenoise]
            elif(key == ord('v')):
                tools = [getFrame , getMarkers , applyContours , invertColors]
            elif(key == ord('p')):
                pauseAll = not pauseAll
            elif(key == ord('+')):
                mainAux.l_col += 0.1
            elif(key == ord('-')):
                mainAux.l_col -= 0.1
                if(mainAux.l_col < 0.2):
                    mainAux.l_col = 0.2

    finally:

        mainAux.cap.release()
        cv2.destroyAllWindows()

